{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "RAG (Retrieval-Augmented Generation)\n",
        "RAG enhances the response of language models by combining retrieval and generation:\n",
        "\n",
        "Retrieval: Fetch relevant information from a knowledge base.\n",
        "Generation: Use the LLM to generate a response using the fetched information."
      ],
      "metadata": {
        "id": "rE4JQOKrQdtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLM demonstration using Chatgpt Openai model (different NLP use cases)"
      ],
      "metadata": {
        "id": "R_qmtbWYTmdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag components:"
      ],
      "metadata": {
        "id": "uaVQgxVcT0gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Document Loaders: Load your data.\n",
        "Text Splitters: Break it into manageable pieces.\n",
        "Vector Stores: Store text chunks for fast retrieval.\n",
        "Retrievers: Fetch relevant information.\n",
        "LLM Chains: Combine retrieval with language models.\n"
      ],
      "metadata": {
        "id": "8jcHwl3zQ7EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Role of RAG in Generative AI Workflows\n",
        "Improved Accuracy: Access to up-to-date and factual information from external sources reduces hallucinations in generative AI responses.\n",
        "\n",
        "Knowledge Expansion: Models can reference large-scale external knowledge bases instead of relying solely on training data.\n",
        "\n",
        "Efficient Data Handling: Provides context-sensitive responses by searching vast datasets without requiring re-training.\n",
        "\n",
        "Personalization: Tailors responses based on user-specific contexts and external domain-specific data."
      ],
      "metadata": {
        "id": "Lkd0RDsXQ_j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What is LangChain?\n",
        "LangChain is a powerful framework designed to help developers build applications\n",
        " that involve large language models (LLMs) with structured workflows.\n",
        "It enables us to combine LLMs with external data, memory, and tools."
      ],
      "metadata": {
        "id": "9U8fcLoqQsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Document loaders"
      ],
      "metadata": {
        "id": "fPevUSY0Stum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://python.langchain.com/docs/integrations/document_loaders/"
      ],
      "metadata": {
        "id": "IorQvDetQs2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Webpages\n",
        "The below document loaders allow you to load webpages.\n",
        "\n",
        "See this guide for a starting point: How to: load web pages.\n",
        "\n",
        "Document Loader\tDescription\tPackage/API\n",
        "Web\tUses urllib and BeautifulSoup to load and parse HTML web pages\tPackage\n",
        "Unstructured\tUses Unstructured to load and parse web pages\tPackage\n",
        "RecursiveURL\tRecursively scrapes all child links from a root URL\tPackage\n",
        "Sitemap\tScrapes all pages on a given sitemap\tPackage\n",
        "Firecrawl\tAPI service that can be deployed locally, hosted version has free credits.\tAPI\n",
        "Docling\tUses Docling to load and parse web pages\tPackage\n",
        "Hyperbrowser\tPlatform for running and scaling headless browsers, can be used to scrape/crawl any site\tAPI\n",
        "PDFs\n",
        "The below document loaders allow you to load PDF documents.\n",
        "\n",
        "See this guide for a starting point: How to: load PDF files.\n",
        "\n",
        "Document Loader\tDescription\tPackage/API\n",
        "PyPDF\tUses `pypdf` to load and parse PDFs\tPackage\n",
        "Unstructured\tUses Unstructured's open source library to load PDFs\tPackage\n",
        "Amazon Textract\tUses AWS API to load PDFs\tAPI\n",
        "MathPix\tUses MathPix to load PDFs\tPackage\n",
        "PDFPlumber\tLoad PDF files using PDFPlumber\tPackage\n",
        "PyPDFDirectry\tLoad a directory with PDF files\tPackage\n",
        "PyPDFium2\tLoad PDF files using PyPDFium2\tPackage\n",
        "PyMuPDF\tLoad PDF files using PyMuPDF\tPackage\n",
        "PDFMiner\tLoad PDF files using PDFMiner\tPackage\n",
        "Upstage Document Parse Loader\tLoad PDF files using UpstageDocumentParseLoader\tPackage\n",
        "Docling\tLoad PDF files using Docling\tPackage\n",
        "Cloud Providers\n",
        "The below document loaders allow you to load documents from your favorite cloud providers.\n",
        "\n",
        "Document Loader\tDescription\tPartner Package\tAPI reference\n",
        "AWS S3 Directory\tLoad documents from an AWS S3 directory\t❌\tS3DirectoryLoader\n",
        "AWS S3 File\tLoad documents from an AWS S3 file\t❌\tS3FileLoader\n",
        "Azure AI Data\tLoad documents from Azure AI services\t❌\tAzureAIDataLoader\n",
        "Azure Blob Storage Container\tLoad documents from an Azure Blob Storage container\t❌\tAzureBlobStorageContainerLoader\n",
        "Azure Blob Storage File\tLoad documents from an Azure Blob Storage file\t❌\tAzureBlobStorageFileLoader\n",
        "Dropbox\tLoad documents from Dropbox\t❌\tDropboxLoader\n",
        "Google Cloud Storage Directory\tLoad documents from GCS bucket\t✅\tGCSDirectoryLoader\n",
        "Google Cloud Storage File\tLoad documents from GCS file object\t✅\tGCSFileLoader\n",
        "Google Drive\tLoad documents from Google Drive (Google Docs only)\t✅\tGoogleDriveLoader\n",
        "Huawei OBS Directory\tLoad documents from Huawei Object Storage Service Directory\t❌\tOBSDirectoryLoader\n",
        "Huawei OBS File\tLoad documents from Huawei Object Storage Service File\t❌\tOBSFileLoader\n",
        "Microsoft OneDrive\tLoad documents from Microsoft OneDrive\t❌\tOneDriveLoader\n",
        "Microsoft SharePoint\tLoad documents from Microsoft SharePoint\t❌\tSharePointLoader\n",
        "Tencent COS Directory\tLoad documents from Tencent Cloud Object Storage Directory\t❌\tTencentCOSDirectoryLoader\n",
        "Tencent COS File\tLoad documents from Tencent Cloud Object Storage File\t❌\tTencentCOSFileLoader\n",
        "Social Platforms\n",
        "The below document loaders allow you to load documents from different social media platforms.\n",
        "\n",
        "Document Loader\tAPI reference\n",
        "Twitter\tTwitterTweetLoader\n",
        "Reddit\tRedditPostsLoader"
      ],
      "metadata": {
        "id": "xc_IKePVSUjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Embedding models"
      ],
      "metadata": {
        "id": "ELVJWEVWSpTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://python.langchain.com/docs/integrations/text_embedding/"
      ],
      "metadata": {
        "id": "RUT5_g4xSboY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Provider\tPackage\n",
        "AzureOpenAI\tlangchain-openai\n",
        "Ollama\tlangchain-ollama\n",
        "AI21\tlangchain-ai21\n",
        "Fake\tlangchain-core\n",
        "OpenAI\tlangchain-openai\n",
        "Together\tlangchain-together\n",
        "Fireworks\tlangchain-fireworks\n",
        "MistralAI\tlangchain-mistralai\n",
        "Cohere\tlangchain-cohere\n",
        "Nomic\tlangchain-nomic\n",
        "Databricks\tdatabricks-langchain\n",
        "VoyageAI\tlangchain-voyageai\n",
        "IBM\tlangchain-ibm\n",
        "NVIDIA\tlangchain-nvidia"
      ],
      "metadata": {
        "id": "46U5rRrTSdzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vector stores"
      ],
      "metadata": {
        "id": "mIkhZYZESlv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://python.langchain.com/docs/integrations/vectorstores/"
      ],
      "metadata": {
        "id": "_8_YXgIwSiR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vectorstore\tDelete by ID\tFiltering\tSearch by Vector\tSearch with score\tAsync\tPasses Standard Tests\tMulti Tenancy\tIDs in add Documents\n",
        "AstraDBVectorStore\t    ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "Chroma\t                ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "Clickhouse\t            ✅\t✅\t❌\t✅\t❌\t❌\t❌\t❌\n",
        "CouchbaseVectorStore    ✅\t✅\t❌\t✅\t✅\t❌\t❌\t❌\n",
        "DatabricksVectorSearch\t✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "ElasticsearchStore\t    ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "FAISS\t                  ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "InMemoryVectorStore\t    ✅\t✅\t❌\t✅\t✅\t❌\t❌\t❌\n",
        "Milvus\t                ✅\t✅\t❌\t✅\t✅\t❌\t❌\t❌\n",
        "MongoDBAtlasVectorSearch✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "PGVector\t              ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "PineconeVectorStore\t    ✅\t✅\t✅\t❌\t✅\t❌\t❌\t❌\n",
        "QdrantVectorStore\t      ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "Redis\t                  ✅\t✅\t✅\t✅\t✅\t❌\t❌\t❌\n",
        "Weaviate\t              ✅\t✅\t✅\t✅\t✅\t❌\t✅\t❌\n",
        "SQLServer\t              ✅\t✅\t✅\t✅\t❌\t❌\t❌\t❌"
      ],
      "metadata": {
        "id": "7o3rDaRgSzD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5kxAN4Yuu4c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import streamlit as st\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit UI\n",
        "st.title(\"RAG Application for PDF Information Extraction\")\n",
        "\n",
        "# Step 1: User uploads a PDF\n",
        "uploaded_pdf = st.file_uploader(\"Upload a PDF\", type=[\"pdf\"])\n"
      ],
      "metadata": {
        "id": "hd8rL-poTS5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Input OpenAI API Key from the user\n",
        "api_key = st.text_input(\"Enter your OpenAI API Key\", type=\"password\")\n"
      ],
      "metadata": {
        "id": "sjlEUVVATeNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if uploaded_pdf and api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "    # Step 3: Extract text from the PDF\n",
        "    def extract_text_from_pdf(pdf_file):\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "\n",
        "    pdf_text = extract_text_from_pdf(uploaded_pdf)\n",
        "\n",
        "    # Display the extracted PDF text (optional for debugging)\n",
        "    with st.expander(\"Extracted Text from PDF\"):\n",
        "        st.write(pdf_text)\n",
        "\n",
        "    # Step 4: Initialize OpenAI LLM and Embeddings\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    # Step 5: Create FAISS Vector Store\n",
        "    from langchain.text_splitter import CharacterTextSplitter\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_text(pdf_text)\n",
        "\n",
        "    # Embed the text chunks and store in FAISS\n",
        "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "    # Step 6: Create the RAG Chain\n",
        "    retriever = vector_store.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=OpenAI(model_name=\"gpt-3.5-turbo\"),\n",
        "        retriever=retriever\n",
        "    )\n"
      ],
      "metadata": {
        "id": "nI1ZGjlCTVy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Step 7: User asks a question\n",
        "    user_query = st.text_input(\"Ask a question about the PDF content:\")\n",
        "\n",
        "    if user_query:\n",
        "        # Get the answer using RAG\n",
        "        answer = qa_chain.run(user_query)\n",
        "        st.write(\"**Answer:**\", answer)\n",
        "else:\n",
        "    st.warning(\"Please upload a PDF and enter a valid OpenAI API Key.\")"
      ],
      "metadata": {
        "id": "a1ee5ddITUyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}